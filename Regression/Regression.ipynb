{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6QoanhzAAVaxK+V+MdeDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samruddhi-saoji/Assignment-tracker/blob/master/Regression/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple Linear Regression"
      ],
      "metadata": {
        "id": "Tvgj0MYuXLZY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpe5qwzNXDrA"
      },
      "outputs": [],
      "source": [
        "#data pre-processing############################################################\n",
        "#importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#importing dataset\n",
        "dataset = pd.read_csv('Salary_Data.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "#splitting dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
        "\n",
        "\n",
        "#training the SLR model on test set#############################################\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#object of LinearRegression class\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#training the regressor\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#predicting test results########################################################\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#visualising the results #######################################################\n",
        "#training set results ########\n",
        "#plotting the graph\n",
        "plt.scatter(X_train, y_train, color = 'red')\n",
        "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
        "\n",
        "#extra details\n",
        "plt.title('Salary vs Experience (Training set)')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "#print the graph\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#test set results ########\n",
        "#plotting the graph\n",
        "plt.scatter(X_test, y_test, color = 'red')\n",
        "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
        "\n",
        "#extra details\n",
        "plt.title('Salary vs Experience (Test set)')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "#print the graph\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multiple Linear Regression"
      ],
      "metadata": {
        "id": "uSBm1t6hXRZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data pre-processing############################################################\n",
        "#importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#importing dataset\n",
        "dataset = pd.read_csv('50_Startups.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "#encoding categorical variables\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "#splitting dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "\n",
        "#training the MLR model on test set#############################################\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#building the model\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#training the model\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#predicting test results########################################################\n",
        "#creating a 1D array of predicted results\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "#printing the predicted values and actual values side by side\n",
        "np.set_printoptions(precision=2) #max 2 decimal places\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "\n",
        "#  np.concatenate((A1, A2, A3) , axis)\n",
        "    # (A1, A2, A3) : tupple of arrays to be concat\n",
        "    # axis : 0=horizontal , 1=vertical\n",
        "\n",
        "# for 1D array arr:\n",
        "# arr.reshape( array length, 1) will\n",
        "# display the array vertically instead of horizontally\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "ym5QRp73XYc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Polynomial Linear Regression"
      ],
      "metadata": {
        "id": "8okwPqv_XZEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data pre-processing############################################################\n",
        "#importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#importing dataset\n",
        "dataset = pd.read_csv('Position_Salaries.csv')\n",
        "\n",
        "#here the entire dataset is the training set\n",
        "#col index 1 is the feature\n",
        "X_train = dataset.iloc[:, 1:2].values\n",
        "#you need to write 1:2 instead of just 1\n",
        "#else you get error #why???\n",
        "\n",
        "#last col is the dependent var\n",
        "y_train = dataset.iloc[:, -1].values\n",
        "\n",
        "\n",
        "#training the PLR model on whole dataset#############################################\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "#polynomial regressor\n",
        "regressor = PolynomialFeatures(degree = 4)\n",
        "\n",
        "#matrix of powered features (x1^n)\n",
        "X_poly = regressor.fit_transform(X_train)\n",
        "#this is the new matrix of feature \n",
        "#aka new X_train\n",
        "\n",
        "#linear regressor  \n",
        "lin_reg = LinearRegression()\n",
        "#MLR on dataset\n",
        "lin_reg.fit(X_poly, y_train)\n",
        "\n",
        "#predicting new value #########################################################\n",
        "# predicting the salary of someone at level 6.5\n",
        "lin_reg.predict(regressor.fit_transform([[6.5]]))\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#visualising the PLR results #######################################################\n",
        "#PLR results ########\n",
        "#observations\n",
        "plt.scatter(X_train, y_train, color = 'red') \n",
        "\n",
        "#best fitting line(curve)\n",
        "plt.plot(X_train,   lin_reg.predict(regressor.fit_transform(X_train)),   color = 'blue')\n",
        "#X values = X_train\n",
        "#Y values = y values predicted based on new matrix of features (X_poly)\n",
        "    # regressor.fit_transform(X_train) ==> X_poly\n",
        "# colour of line = blue\n",
        "\n",
        "#labelling\n",
        "plt.title('Truth or Bluff (Polynomial Regression)')\n",
        "plt.xlabel('Position level')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "#display graph\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jTH-UrKBXfzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Regression"
      ],
      "metadata": {
        "id": "j1-wUwAeXglF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data pre-processing############################################################\n",
        "#importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#importing dataset################\n",
        "dataset = pd.read_csv('Position_Salaries.csv')\n",
        "\n",
        "#here the entire dataset is the training set\n",
        "#col index 1 is the feature\n",
        "X_train = dataset.iloc[:, 1:2].values\n",
        "\n",
        "#last col is the dependent var\n",
        "y_train = dataset.iloc[:, -1].values\n",
        "\n",
        "#convert y_train to 2D array\n",
        "#reason: std scaler expects a 2d array\n",
        "y_train = y_train.reshape(len(y_train), 1 )\n",
        "\n",
        "# X_train is already 2D\n",
        "\n",
        "#feature scaling#################\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#here we will scale both features and DV\n",
        "    #this is bcs DV can take any value\n",
        "\n",
        "#scalers\n",
        "sc_X = StandardScaler() \n",
        "sc_y = StandardScaler()\n",
        "# two scalers are needed bcs both scalers \n",
        "# will be storing mean,dev of cols in different matrices\n",
        "\n",
        "#scaling\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "    #fit => mean,std dev of all cols in X_train will be calculated\n",
        "    #their values will be stored in the scaler sc_X\n",
        "    #those values will be used in transform()\n",
        "    #transform => transform X_train matrix\n",
        "    #updated matrix will be returned\n",
        "\n",
        "y_train = sc_y.fit_transform(y_train)\n",
        "    #fit => mean,std dev of all cols in y_train will be calculated\n",
        "    #their values will be stored in the scaler sc_y\n",
        "    #those values will be used to transform y_train matrix\n",
        "    #updated matrix will be returned\n",
        "\n",
        "\n",
        "#training the SVR model on whole dataset#############################################\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "#object of LinearRegression class\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#training the regressor\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#predicting test results########################################################\n",
        "sc_y.inverse_transform( regressor.predict(sc_X.transform([[6.5]])).reshape(-1,1) )\n",
        "\n",
        "#we have scaled both X_train, y_train using different scalers\n",
        "# sc_X.transform([[6.5]]) ==> scales 6.5 a/c to the scaling applied to X_train\n",
        "# regressor.predict(scaled 6.5) ==> returns a 2d matrix of predicted y value\n",
        "# predictedMatrix.reshape(-1,1) ==> converts 2d matrix to 1d\n",
        "    #matrix of predicted value aka pmat\n",
        "# the predicted value in pmat will be in the y scale\n",
        "#sc_y.inverse_transform( pmat ) => reverses the scaling of y scaler sc_y\n",
        "#thus the final value is the predicted Y value in its original scale\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#visualising the results #######################################################\n",
        "#plotting actual values\n",
        "plt.scatter(sc_X.inverse_transform(X_train), sc_y.inverse_transform(y_train), color = 'red')\n",
        "\n",
        "#plot predicted values\n",
        "plt.plot(sc_X.inverse_transform(X_train), sc_y.inverse_transform(regressor.predict(X_train)), color = 'blue')\n",
        "\n",
        "#labelling\n",
        "plt.title('Truth or Bluff (SVR)')\n",
        "plt.xlabel('Position level')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "#print graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E4xxcAxOXkz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree Regression"
      ],
      "metadata": {
        "id": "hKXZ4QJwXlWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#import dataset\n",
        "dataset = pd.read_csv('Position_Salaries.csv')\n",
        "\n",
        "#create the matrices of features and DV\n",
        "  #here entire dataset is training set\n",
        "X_train = dataset.iloc[:, 1:-1].values\n",
        "y_train = dataset.iloc[:, -1].values\n",
        "\n",
        "#train DTR model on training set\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor(random_state = 0)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "#predict the DV value for X=6.5\n",
        "regressor.predict([[6.5]])\n",
        "\n",
        "\n",
        "###################################################\n",
        "#plot the graph of real, predicted values \n",
        "#using grids for better resolution and smoother curve\n",
        "X_grid = np.arange(min(X_train), max(X_train), 0.01)\n",
        "X_grid = X_grid.reshape((len(X_grid), 1))\n",
        "\n",
        "#actual observations\n",
        "plt.scatter(X_train, y_train, color='red')  \n",
        "#predicted values   # (x, f(x) , colour)\n",
        "plt.plot(X_grid, regressor.predict(X_grid), color='blue')\n",
        "\n",
        "#labelling the graph\n",
        "plt.title('Truth or Bluff (Decision Tree Regression)')\n",
        "plt.xlabel('Position level')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "#display the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eJc4-d4gXoxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest Regression"
      ],
      "metadata": {
        "id": "znoe2XIIXqk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#importing dataset\n",
        "dataset = pd.read_csv('Position_Salaries.csv')\n",
        "\n",
        "#create the matrices of features and DV\n",
        "  #entire dataset is training set\n",
        "X_train = dataset.iloc[:, 1:-1].values\n",
        "y_train = dataset.iloc[:, -1].values\n",
        "\n",
        "\n",
        "#training RFR model on training set\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
        "      #n_estimators --> number of trees to build\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#predicting the new result\n",
        "regressor.predict([[6.5]])\n",
        "\n",
        "\n",
        "############################################################################\n",
        "#visualising the predictions\n",
        "\n",
        "#using grids for smoother curve\n",
        "X_grid = np.arange(min(X_train), max(X_train), 0.01)\n",
        "X_grid = X_grid.reshape((len(X_grid), 1))\n",
        "\n",
        "#plotting the graph\n",
        "#actual observations\n",
        "plt.scatter(X_train, y_train, color = 'red')\n",
        "#predicted values   # (x, f(x) , colour)\n",
        "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
        "\n",
        "#labelling the graph\n",
        "plt.title('Truth or Bluff (Random Forest Regression)')\n",
        "plt.xlabel('Position level')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "#display the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z2JCtM4UXtW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}